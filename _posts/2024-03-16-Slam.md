---
layout: post
title:  "Simultaneous Localization and Mapping from Scratch (EKF SLAM)"
categories: [Machine Learning, ROS 2 , C++, EKF SLAM ]
image: assets/images/thumbnail_slam.png
featured: false
hidden: false
---
Developing an EKF SLAM algorithm from scratch using C++ and ROS 2 for a turtlebot3 robot. A simulation environment is being developed in Rviz2 to test the algorithm.

## Overview
This post is a work in progess. The final post will be available by March 16, 2024.

The red robot represents the ground truth, the blue robot represents the odometry and the green robot represents the estimated position of the robot using the EKF SLAM algorithm.
The green landmark represents the estimated position of the obstacles using the EKF SLAM algorithm.
The yellow obstacles reprent the simulated sensor data.

## SLAM without collision
Here is a picture of the robot's path when it does not encounter a collision. The red robot representing the ground truth, the blue robot representing the odometry and the green robot representing the estimated position of the robot using the EKF SLAM algorithm are all in the same position.

<div align="center"><img src="https://raw.githubusercontent.com/roy2909/roy2909.github.io/commit/01d1132ba9c8d14e084c9a11d2149fe5f9648274/assets/images/slam_no_collision.png alt="slam_no_coll" width="600"/></div>



## SLAM with collision
The picture below shows the robot's path when it encounters a collision. The red robot and the green robot are estimated to be at the same position. The blue robot representing the odometry is far from the ground truth, as seen in the picture. The EKF SLAM algorithm is able to estimate the position of the robot even when the odometry is not reliable.

<div align="center"><img src="https://raw.githubusercontent.com/roy2909/roy2909.github.io/commit/01d1132ba9c8d14e084c9a11d2149fe5f9648274/assets/images/slam_collision.png alt="slam_coll" width="600"/></div>



## Simultaneous Localization and Mapping (SLAM) wiyhout collision
The following video shows the algorithm in action. The red robot represents the ground truth, the blue robot represents the odometry and the green robot represents the estimated position of the robot using the EKF SLAM algorithm. Here you can see all three robots superimposd on each other, indicating that the EKF SLAM algorithm is able to estimate the position of the robot accurately.

<iframe width="560" height="315" src="https://www.youtube.com/embed/TmuXMLChOyA " frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


## Simultaneous Localization and Mapping (SLAM) with collision
The following video shows the EKF SLAM algorithm in action when the robot encounters a collision. The red robot and the green robot are estimated to be at the same position. The blue robot representing the odometry is far from the ground truth, as seen in the video. The EKF SLAM algorithm is able to estimate the position of the robot even when the odometry is not reliable.

<iframe width="560" height="315" src="https://www.youtube.com/embed/M7z6BmtaPaM " frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


