---
layout: post
title:  "Automated Grasping: Pincher X100 4-DOF Robot Arm Grasps a Purple Pen"
categories: [ Computer Vision, OpenCV, Python, PincherX 100, Intel Realsense ]
image: assets/images/pen.jpg
featured: false
hidden: false
---
Programmed a Pincher X100 4-DOF robot arm to grasp a purple colored pen.

## Overview

<div align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/SmPIuWhf_UQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>

I utilized an Intel Realsense D435i camera to locate a purple Northwestern pen and manipulate it using a Trossen PincherX 100 robot arm. My approach involved an initial transformation of the Realsense RGB image into the HSV color space, enabling the extraction of all purple-hued pixels using their specific HSV values. This selection formed a binary map, designating the identified pixels as white while rendering all other pixels black.

Leveraging OpenCV's contour detection capabilities, I determined the exact pixel coordinates representing the pen's centroid. This information was pivotal in establishing the pen's spatial orientation concerning the camera. By aligning this data with the depth image provided by the Realsense, I precisely mapped the pen's position in the camera's frame.

Subsequently, through a conversion process, I translated the pen's position from the camera's frame to the robot's frame. This enabled the seamless coordination of the robot arm's movements towards the pen, allowing it to navigate and securely grasp the targeted object.

 Centroid and thresholding of the purple pen
 <div align="center"><img src="https://raw.githubusercontent.com/roy2909/roy2909.github.io/08b08e279ba67fb56615d4048d3c89ace9d4a978/assets/images/penC.gif" alt="car_setup" width="600"/></div>
 &nbsp;
<div align="center"><h4> <a href="https://github.com/roy2909/pen_challenge">View it on Github</a></h4></div>
