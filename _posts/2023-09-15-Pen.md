---
layout: post
title:  "Automated Grasping: Pincher X100 4-DOF Robot Arm -Picks a Purple Pen"
categories: [ Computer Vision, OpenCV, Python, PincherX 100, Intel Realsense ]
image: assets/images/pen.jpg
featured: false
hidden: false
---
Programmed a Pincher X100 4-DOF robot arm to grasp a purple colored pen.

## Overview

<div align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/SmPIuWhf_UQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>

 I utilized an Intel Realsense D435i camera to locate a purple Northwestern pen and manipulate it using a Trossen PincherX 100 robot arm. To identify the pen's position, I transformed the RGB image from the Realsense into an HSV image and employed the HSV values to identify all purple-hued pixels. Following this, I established a binary map where the identified pixels were depicted as white and all other pixels as black. Utilizing OpenCV's contour detection, I determined the pixel coordinates of the pen's centroid. This enabled me to ascertain the pen's position in relation to the camera by utilizing the aligned depth image generated by the Realsense. Subsequently, I converted the pen's position from the camera's frame to that of the frame of the robot and directed the robot to maneuver towards the pen and seize it.

 Centroid and thresholding of the purple pen
 <div align="center"><img src="https://raw.githubusercontent.com/roy2909/roy2909.github.io/08b08e279ba67fb56615d4048d3c89ace9d4a978/assets/images/penC.gif" alt="car_setup" width="600"/></div>
 &nbsp;
<div align="center"><h4> <a href="https://github.com/roy2909/pen_challenge">View it on Github</a></h4></div>
